server:
  base_url: "http://127.0.0.1:8080/completion"
  model_alias: "llama-2-7b-chat"

workload:
  users: 20               # Increased to 20 for higher stress
  duration_seconds: 120   # Increased duration for better stats
  ramp_up_seconds: 10     # Time to reach full concurrency (0 for static)
  seed: 42                # Deterministic PRNG seed

prompts:
  min_tokens: 50
  max_tokens: 200
  prefix: "Please summarize the following text: "
